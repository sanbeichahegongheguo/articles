# 机器学习和数据挖掘中的十大算法

[TOC]

## 1、C4.5算法  ID3算法

### 1.1 介绍

C4.5，是机器学习算法中的一个分类决策树算法，它是决策树(决策树也就是做决策的节点间的组织方式像一棵树，其实是一个倒树)核心算法ID3的改进算法，所以基本上了解了一半决策树构造方法就能构造它。决策树构造方法其实就是每次选择一个好的特征以及分裂点作为当前节点的分类条件。

机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。
从数据产生决策树的机器学习技术叫做决策树学习, 通俗说就是决策树。

决策树学习也是数据挖掘中一个普通的方法。在这里，每个决策树都表述了一种树型结构，他由他的分支来对该类型的对象依靠属性进行分类。每个决策树可以依靠对源数据库的分割进行数据测试。这个过程可以递归式的对树进行修剪。 当不能再进行分割或一个单独的类可以被应用于某一分支时，递归过程就完成了。另外，随机森林分类器将许多决策树结合起来以提升分类的正确率。

决策树同时也可以依靠计算条件概率来构造。决策树如果依靠数学的计算方法可以取得更加理想的效果。

- 决策树是如何工作的

决策树一般都是自上而下的来生成的。

选择分割的方法有好几种，但是目的都是一致的：对目标类尝试进行最佳的分割。

从根到叶子节点都有一条路径，这条路径就是一条“规则”。

决策树可以是二叉的，也可以是多叉的。

对每个节点的衡量：

1. 通过该节点的记录；
2. 如果是叶子节点的话，分类的路径；
3. 对叶子节点正确分类的比例。

有些规则的效果可以比其他的一些规则要好。

### 1.2 ID3 算法

1. 概念提取算法CLS

   1. 初始化参数 C={E},E 包括所有的例子,为根.

   2. ```C
      IF C 中的任一元素 e 同属于同一个决策类则创建一个叶子
      	节点 YES 终止.
      ELSE 依启发式标准,选择特征 Fi={V1,V2,V3,．．．Vn}并创建
      	判定节点
      ```
      划分 C 为互不相交的 N 个集合 C1,C2,C3,．．．,Cn；
   3. 

      




由于 ID3 算法在实际应用中存在一些问题，于是 Quilan 提出了 C4.5 算法，严格上说 C4.5 只能是 ID3 的一个改进算法。

## 2、K-mean算法

3、Svm算法

4、Apriori算法

5、EM算法

6、PageRank算法

7、AdaBoost算法

8、kNN算法

9、Naive Baye算法

10、CART算法

```

```